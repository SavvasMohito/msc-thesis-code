{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Test Individual Crews\n",
        "\n",
        "This notebook allows you to test and debug each crew independently.\n",
        "\n",
        "**Setup:**\n",
        "1. Make sure your `.env` file has OPENAI_API_KEY\n",
        "2. Run cells in order (or jump to specific crew)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import json\n",
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, str(Path.cwd() / \"src\"))\n",
        "\n",
        "# Load environment\n",
        "load_dotenv()\n",
        "\n",
        "# Set OpenAI model for CrewAI\n",
        "os.environ[\"OPENAI_MODEL_NAME\"] = \"gpt-4o-mini\"  # or gpt-4o, gpt-4-turbo\n",
        "# Verify API key is loaded\n",
        "if not os.getenv(\"OPENAI_API_KEY\"):\n",
        "    print(\"âš ï¸  WARNING: OPENAI_API_KEY not found in environment!\")\n",
        "    print(\"   Please add it to your .env file\")\n",
        "else:\n",
        "    print(\"âœ“ OpenAI API key loaded\")\n",
        "    print(f\"âœ“ Using model: {os.getenv('OPENAI_MODEL_NAME')}\")\n",
        "\n",
        "print(\"âœ“ Setup complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Weaviate Configuration and Health Check\n",
        "import weaviate\n",
        "\n",
        "# Set Weaviate connection parameters\n",
        "os.environ.setdefault(\"WEAVIATE_HOST\", \"localhost\")\n",
        "os.environ.setdefault(\"WEAVIATE_PORT\", \"8080\")\n",
        "os.environ.setdefault(\"WEAVIATE_GRPC_PORT\", \"50051\")\n",
        "\n",
        "print(\"Checking Weaviate connection...\")\n",
        "try:\n",
        "    client = weaviate.connect_to_local(\n",
        "        host=os.getenv(\"WEAVIATE_HOST\"),\n",
        "        port=int(os.getenv(\"WEAVIATE_PORT\")),\n",
        "        grpc_port=int(os.getenv(\"WEAVIATE_GRPC_PORT\")),\n",
        "    )\n",
        "\n",
        "    # Check if connected\n",
        "    if client.is_ready():\n",
        "        print(\"âœ“ Weaviate is connected and ready\")\n",
        "\n",
        "        # Check if SecurityControl collection exists\n",
        "        if client.collections.exists(\"SecurityControl\"):\n",
        "            collection = client.collections.get(\"SecurityControl\")\n",
        "            # Try to count objects (may not work in all versions)\n",
        "            print(\"âœ“ SecurityControl collection exists\")\n",
        "        else:\n",
        "            print(\"âš ï¸  WARNING: SecurityControl collection does not exist!\")\n",
        "            print(\"   Run: python -m security_requirements_system.tools.weaviate_setup\")\n",
        "    else:\n",
        "        print(\"âš ï¸  WARNING: Weaviate is not ready\")\n",
        "\n",
        "    client.close()\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ ERROR: Cannot connect to Weaviate: {e}\")\n",
        "    print(f\"   Make sure Weaviate is running on {os.getenv('WEAVIATE_HOST')}:{os.getenv('WEAVIATE_PORT')}\")\n",
        "    print(\"   Start with: docker-compose up -d\")\n",
        "    print(\"\\nWeaviate Configuration:\")\n",
        "    print(f\"  Host: {os.getenv('WEAVIATE_HOST')}\")\n",
        "    print(f\"  Port: {os.getenv('WEAVIATE_PORT')}\")\n",
        "    print(f\"  gRPC Port: {os.getenv('WEAVIATE_GRPC_PORT')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "\n",
        "\n",
        "def display_crew_output(result, crew_name):\n",
        "    \"\"\"Display crew output in a readable format.\"\"\"\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"{crew_name} OUTPUT\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    if hasattr(result, \"raw\"):\n",
        "        print(\"RAW OUTPUT:\")\n",
        "        print(result.raw[:500] + \"...\" if len(result.raw) > 500 else result.raw)\n",
        "\n",
        "    if hasattr(result, \"pydantic\") and result.pydantic:\n",
        "        print(\"\\nSTRUCTURED OUTPUT:\")\n",
        "        print(json.dumps(result.pydantic.model_dump(), indent=2, default=str)[:1000])\n",
        "\n",
        "    if hasattr(result, \"tasks_output\"):\n",
        "        print(f\"\\nTASKS: {len(result.tasks_output)}\")\n",
        "        for i, task in enumerate(result.tasks_output):\n",
        "            task_name = task.name if hasattr(task, \"name\") else f\"Task {i}\"\n",
        "            print(f\"  {i+1}. {task_name}\")\n",
        "            if hasattr(task, \"pydantic\") and task.pydantic:\n",
        "                print(f\"     Type: {type(task.pydantic).__name__}\")\n",
        "\n",
        "\n",
        "def save_output(result, crew_name, output_dir=\"test_outputs\"):\n",
        "    \"\"\"Save crew output to JSON file.\"\"\"\n",
        "    output_path = Path(output_dir)\n",
        "    output_path.mkdir(exist_ok=True)\n",
        "\n",
        "    output_file = output_path / f\"{crew_name}_output.json\"\n",
        "\n",
        "    data = {}\n",
        "    if hasattr(result, \"raw\"):\n",
        "        data[\"raw\"] = result.raw\n",
        "    if hasattr(result, \"pydantic\") and result.pydantic:\n",
        "        data[\"pydantic\"] = result.pydantic.model_dump()\n",
        "    if hasattr(result, \"tasks_output\"):\n",
        "        data[\"tasks\"] = []\n",
        "        for task in result.tasks_output:\n",
        "            task_data = {\"name\": task.name if hasattr(task, \"name\") else \"unknown\", \"raw\": task.raw if hasattr(task, \"raw\") else str(task)}\n",
        "            if hasattr(task, \"pydantic\") and task.pydantic:\n",
        "                task_data[\"pydantic\"] = task.pydantic.model_dump()\n",
        "            data[\"tasks\"].append(task_data)\n",
        "\n",
        "    with open(output_file, \"w\") as f:\n",
        "        json.dump(data, f, indent=2, default=str)\n",
        "\n",
        "    print(f\"\\nðŸ’¾ Saved to: {output_file}\")\n",
        "    return output_file\n",
        "\n",
        "\n",
        "def load_cached_output(crew_name, output_dir=\"test_outputs\"):\n",
        "    \"\"\"Load cached crew output from JSON file if it exists.\"\"\"\n",
        "    output_file = Path(output_dir) / f\"{crew_name}_output.json\"\n",
        "\n",
        "    if output_file.exists():\n",
        "        with open(output_file, \"r\") as f:\n",
        "            data = json.load(f)\n",
        "        print(f\"ðŸ“‚ Loaded cached output from: {output_file}\")\n",
        "        return data\n",
        "    else:\n",
        "        print(f\"âš ï¸  No cached output found for {crew_name}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "print(\"âœ“ Helper functions loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Cached Outputs\n",
        "\n",
        "Each crew cell below will automatically load required data from cached JSON files if the variables don't exist in memory. This allows you to:\n",
        "- Jump to any crew without running previous cells\n",
        "- Reuse outputs from previous runs\n",
        "- Speed up testing\n",
        "\n",
        "If a required cache file is missing, you'll see an error prompting you to run the prerequisite crew first.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample requirements text\n",
        "\n",
        "SAMPLE_REQUIREMENTS = \"\"\"\n",
        "E-commerce Platform Requirements:\n",
        "\n",
        "1. User Management\n",
        "   - User registration and login\n",
        "   - Multi-factor authentication\n",
        "   - Password reset functionality\n",
        "   - Profile management\n",
        "\n",
        "2. Product Catalog\n",
        "   - Browse products by category\n",
        "   - Search functionality\n",
        "   - Product details and images\n",
        "   - Inventory management\n",
        "\n",
        "3. Shopping Cart & Checkout\n",
        "   - Add/remove items from cart\n",
        "   - Secure payment processing (credit cards, PayPal)\n",
        "   - Order confirmation emails\n",
        "   - Shipping address management\n",
        "\n",
        "4. Order Management\n",
        "   - Order history\n",
        "   - Order tracking\n",
        "   - Returns and refunds\n",
        "\n",
        "5. Admin Panel\n",
        "   - User management\n",
        "   - Product management\n",
        "   - Order processing\n",
        "   - Sales analytics\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ“ Sample requirements loaded\")\n",
        "print(f\"Length: {len(SAMPLE_REQUIREMENTS)} characters\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper: Load all cached outputs (run this to load dependencies)\n",
        "\n",
        "\n",
        "def load_all_dependencies():\n",
        "    \"\"\"Load all crew outputs from cache into memory.\"\"\"\n",
        "    global analysis_output, architecture_output, stakeholder_output\n",
        "    global threat_output, domain_output, ai_security_output, compliance_output\n",
        "    global security_architecture_output, roadmap_output, verification_output, validation_output\n",
        "    global components_json, threats_json, security_controls_json\n",
        "\n",
        "    from src.security_requirements_system.data_models import (\n",
        "        AnalysisOutput,\n",
        "        ArchitectureOutput,\n",
        "        ThreatModelingOutput,\n",
        "        DomainSecurityOutput,\n",
        "    )\n",
        "\n",
        "    # 1. Requirements Analysis\n",
        "    if cached := load_cached_output(\"requirements_analysis\"):\n",
        "        analysis_task = next((t for t in cached[\"tasks\"] if t[\"name\"] == \"analyze_requirements\"), None)\n",
        "        arch_task = next((t for t in cached[\"tasks\"] if t[\"name\"] == \"analyze_architecture\"), None)\n",
        "\n",
        "        if analysis_task and \"pydantic\" in analysis_task:\n",
        "            analysis_output = AnalysisOutput(**analysis_task[\"pydantic\"])\n",
        "        if arch_task and \"pydantic\" in arch_task:\n",
        "            architecture_output = ArchitectureOutput(**arch_task[\"pydantic\"])\n",
        "            components_json = json.dumps([c for c in arch_task[\"pydantic\"][\"components\"]])\n",
        "\n",
        "    # 2. Stakeholder\n",
        "    if cached := load_cached_output(\"stakeholder\"):\n",
        "        stakeholder_output = cached.get(\"raw\", \"\")\n",
        "\n",
        "    # 3. Threat Modeling\n",
        "    if cached := load_cached_output(\"threat_modeling\"):\n",
        "        if \"pydantic\" in cached:\n",
        "            threat_output = ThreatModelingOutput(**cached[\"pydantic\"])\n",
        "            threats_json = json.dumps(cached[\"pydantic\"])\n",
        "\n",
        "    # 4. Domain Security\n",
        "    if cached := load_cached_output(\"domain_security\"):\n",
        "        if \"tasks\" in cached and len(cached[\"tasks\"]) > 0:\n",
        "            if \"pydantic\" in cached[\"tasks\"][0]:\n",
        "                domain_output = DomainSecurityOutput(**cached[\"tasks\"][0][\"pydantic\"])\n",
        "                security_controls_json = json.dumps(cached[\"tasks\"][0][\"pydantic\"])\n",
        "\n",
        "    # 5. AI/LLM Security\n",
        "    if cached := load_cached_output(\"llm_security\"):\n",
        "        ai_security_output = cached.get(\"raw\", \"\")\n",
        "\n",
        "    # 6. Compliance\n",
        "    if cached := load_cached_output(\"compliance\"):\n",
        "        compliance_output = cached.get(\"raw\", \"\")\n",
        "\n",
        "    # 7. Security Architecture\n",
        "    if cached := load_cached_output(\"security_architecture\"):\n",
        "        security_architecture_output = cached.get(\"raw\", \"\")\n",
        "\n",
        "    # 8. Roadmap\n",
        "    if cached := load_cached_output(\"roadmap\"):\n",
        "        roadmap_output = cached.get(\"raw\", \"\")\n",
        "\n",
        "    # 9. Verification\n",
        "    if cached := load_cached_output(\"verification\"):\n",
        "        verification_output = cached.get(\"raw\", \"\")\n",
        "\n",
        "    # 10. Validation\n",
        "    if cached := load_cached_output(\"validation\"):\n",
        "        if \"tasks\" in cached and len(cached[\"tasks\"]) > 0:\n",
        "            if \"pydantic\" in cached[\"tasks\"][0]:\n",
        "                from security_requirements_system.data_models import ValidationOutput\n",
        "\n",
        "                validation_output = ValidationOutput(**cached[\"tasks\"][0][\"pydantic\"])\n",
        "\n",
        "    print(\"\\nâœ“ All available dependencies loaded from cache\")\n",
        "\n",
        "\n",
        "# Uncomment to auto-load all cached outputs:\n",
        "load_all_dependencies()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 1. Requirements Analysis Crew\n",
        "\n",
        "Analyzes product requirements and extracts security-relevant information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from security_requirements_system.crews.requirements_analysis_crew import AnalysisOutputCrew\n",
        "\n",
        "print(\"Testing Requirements Analysis Crew...\\n\")\n",
        "\n",
        "crew = AnalysisOutputCrew().crew()\n",
        "result = crew.kickoff(inputs={\"requirements_text\": SAMPLE_REQUIREMENTS})\n",
        "\n",
        "display_crew_output(result, \"Requirements Analysis\")\n",
        "save_output(result, \"requirements_analysis\")\n",
        "\n",
        "# Store outputs for downstream crews\n",
        "analysis_task = next(filter(lambda x: x.name == \"analyze_requirements\", result.tasks_output))\n",
        "architecture_task = next(filter(lambda x: x.name == \"analyze_architecture\", result.tasks_output))\n",
        "\n",
        "analysis_output = analysis_task.pydantic\n",
        "architecture_output = architecture_task.pydantic\n",
        "\n",
        "print(f\"\\nâœ“ Application Summary: {analysis_output.application_summary[:150]}...\")\n",
        "print(f\"âœ“ High-level requirements: {len(analysis_output.high_level_requirements)}\")\n",
        "print(f\"âœ“ Architecture: {architecture_output.architecture_summary[:150]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Stakeholder Crew\n",
        "\n",
        "Identifies stakeholders and trust boundaries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from security_requirements_system.crews.stakeholder_crew import StakeholderCrew\n",
        "\n",
        "print(\"Testing Stakeholder Crew...\\n\")\n",
        "\n",
        "# Load dependencies from cache if not in memory\n",
        "if \"architecture_output\" not in globals():\n",
        "    print(\"âš ï¸  Loading dependencies from cache...\")\n",
        "    from security_requirements_system.data_models import ArchitectureOutput\n",
        "\n",
        "    cached = load_cached_output(\"requirements_analysis\")\n",
        "    if cached and \"tasks\" in cached:\n",
        "        arch_task = next((t for t in cached[\"tasks\"] if t[\"name\"] == \"analyze_architecture\"), None)\n",
        "        if arch_task and \"pydantic\" in arch_task:\n",
        "            architecture_output = ArchitectureOutput(**arch_task[\"pydantic\"])\n",
        "\n",
        "crew = StakeholderCrew().crew()\n",
        "result = crew.kickoff(inputs={\"requirements_text\": SAMPLE_REQUIREMENTS, \"architecture_summary\": architecture_output.architecture_summary})\n",
        "\n",
        "display_crew_output(result, \"Stakeholder Analysis\")\n",
        "save_output(result, \"stakeholder\")\n",
        "\n",
        "stakeholder_output = result.raw\n",
        "print(f\"\\nâœ“ Output length: {len(stakeholder_output)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Threat Modeling Crew\n",
        "\n",
        "Performs STRIDE threat modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from security_requirements_system.crews.threat_modeling_crew import ThreatModelingCrew\n",
        "\n",
        "print(\"Testing Threat Modeling Crew...\\n\")\n",
        "\n",
        "# Load dependencies from cache if not in memory\n",
        "if \"architecture_output\" not in globals():\n",
        "    print(\"âš ï¸  Loading dependencies from cache...\")\n",
        "    from security_requirements_system.data_models import ArchitectureOutput\n",
        "\n",
        "    cached = load_cached_output(\"requirements_analysis\")\n",
        "    if cached and \"tasks\" in cached:\n",
        "        arch_task = next((t for t in cached[\"tasks\"] if t[\"name\"] == \"analyze_architecture\"), None)\n",
        "        if arch_task and \"pydantic\" in arch_task:\n",
        "            architecture_output = ArchitectureOutput(**arch_task[\"pydantic\"])\n",
        "\n",
        "# Prepare components JSON\n",
        "components_json = json.dumps([c.model_dump() for c in architecture_output.components]) if architecture_output.components else \"[]\"\n",
        "\n",
        "crew = ThreatModelingCrew().crew()\n",
        "result = crew.kickoff(\n",
        "    inputs={\n",
        "        \"requirements_text\": SAMPLE_REQUIREMENTS,\n",
        "        \"architecture_summary\": architecture_output.architecture_summary,\n",
        "        \"components\": components_json,\n",
        "    }\n",
        ")\n",
        "\n",
        "display_crew_output(result, \"Threat Modeling\")\n",
        "save_output(result, \"threat_modeling\")\n",
        "\n",
        "threat_output = result.pydantic\n",
        "threats_json = json.dumps(threat_output.model_dump())\n",
        "print(f\"\\nâœ“ Threats identified: {len(threat_output.threats)}\")\n",
        "print(f\"\\nTop 5 threats:\")\n",
        "for i, threat in enumerate(threat_output.threats[:5], 1):\n",
        "    print(f\"{i}. {threat.threat_id}: {threat.description[:80]}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Domain Security Crew (OWASP ASVS)\n",
        "\n",
        "Maps requirements to OWASP ASVS controls.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from security_requirements_system.crews.domain_security_crew import DomainSecurityCrew\n",
        "\n",
        "print(\"Testing Domain Security Crew...\\n\")\n",
        "\n",
        "# Load dependencies from cache if not in memory\n",
        "if \"analysis_output\" not in globals():\n",
        "    print(\"âš ï¸  Loading dependencies from cache...\")\n",
        "    from security_requirements_system.data_models import AnalysisOutput\n",
        "\n",
        "    cached = load_cached_output(\"requirements_analysis\")\n",
        "    if cached and \"tasks\" in cached:\n",
        "        analysis_task = next((t for t in cached[\"tasks\"] if t[\"name\"] == \"analyze_requirements\"), None)\n",
        "        if analysis_task and \"pydantic\" in analysis_task:\n",
        "            analysis_output = AnalysisOutput(**analysis_task[\"pydantic\"])\n",
        "\n",
        "crew = DomainSecurityCrew().crew()\n",
        "result = crew.kickoff(inputs={\"high_level_requirements\": json.dumps(analysis_output.high_level_requirements)})\n",
        "\n",
        "display_crew_output(result, \"Domain Security (OWASP)\")\n",
        "save_output(result, \"domain_security\")\n",
        "\n",
        "domain_output = result.tasks_output[0].pydantic\n",
        "security_controls_json = json.dumps(domain_output.model_dump())\n",
        "total_controls = sum(len(rm.owasp_controls) for rm in domain_output.requirements_mapping)\n",
        "\n",
        "print(f\"\\nâœ“ Requirements mapped: {len(domain_output.requirements_mapping)}\")\n",
        "print(f\"âœ“ Total OWASP controls: {total_controls}\")\n",
        "print(f\"âœ“ Recommended ASVS level: {domain_output.recommended_asvs_level}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. LLM Security Crew\n",
        "\n",
        "Identifies AI/ML security requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from security_requirements_system.crews.llm_security_crew import LLMSecurityCrew\n",
        "\n",
        "print(\"Testing LLM Security Crew...\\n\")\n",
        "\n",
        "# Load dependencies from cache if not in memory\n",
        "if \"analysis_output\" not in globals():\n",
        "    print(\"âš ï¸  Loading dependencies from cache...\")\n",
        "    from security_requirements_system.data_models import AnalysisOutput\n",
        "\n",
        "    cached = load_cached_output(\"requirements_analysis\")\n",
        "    if cached and \"tasks\" in cached:\n",
        "        analysis_task = next((t for t in cached[\"tasks\"] if t[\"name\"] == \"analyze_requirements\"), None)\n",
        "        if analysis_task and \"pydantic\" in analysis_task:\n",
        "            analysis_output = AnalysisOutput(**analysis_task[\"pydantic\"])\n",
        "\n",
        "crew = LLMSecurityCrew().crew()\n",
        "result = crew.kickoff(\n",
        "    inputs={\n",
        "        \"requirements_text\": SAMPLE_REQUIREMENTS,\n",
        "        \"analyzed_requirements\": f\"Application Summary: {analysis_output.application_summary}\\nHigh-Level Requirements: {analysis_output.high_level_requirements}\",\n",
        "    }\n",
        ")\n",
        "\n",
        "display_crew_output(result, \"LLM Security\")\n",
        "save_output(result, \"llm_security\")\n",
        "\n",
        "ai_security_output = result.raw\n",
        "print(f\"\\nâœ“ Output length: {len(ai_security_output)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compliance Crew\n",
        "\n",
        "Identifies compliance requirements (GDPR, PCI-DSS, etc.).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from security_requirements_system.crews.compliance_crew import ComplianceCrew\n",
        "\n",
        "print(\"Testing Compliance Crew...\\n\")\n",
        "\n",
        "# Load dependencies from cache if not in memory\n",
        "if \"analysis_output\" not in globals():\n",
        "    print(\"âš ï¸  Loading dependencies from cache...\")\n",
        "    from security_requirements_system.data_models import AnalysisOutput\n",
        "\n",
        "    cached = load_cached_output(\"requirements_analysis\")\n",
        "    if cached and \"tasks\" in cached:\n",
        "        analysis_task = next((t for t in cached[\"tasks\"] if t[\"name\"] == \"analyze_requirements\"), None)\n",
        "        if analysis_task and \"pydantic\" in analysis_task:\n",
        "            analysis_output = AnalysisOutput(**analysis_task[\"pydantic\"])\n",
        "\n",
        "crew = ComplianceCrew().crew()\n",
        "result = crew.kickoff(\n",
        "    inputs={\n",
        "        \"requirements_text\": SAMPLE_REQUIREMENTS,\n",
        "        \"analyzed_requirements\": f\"Application Summary: {analysis_output.application_summary}\\nHigh-Level Requirements: {analysis_output.high_level_requirements}\",\n",
        "    }\n",
        ")\n",
        "\n",
        "display_crew_output(result, \"Compliance\")\n",
        "save_output(result, \"compliance\")\n",
        "\n",
        "compliance_output = result.raw\n",
        "print(f\"\\nâœ“ Output length: {len(compliance_output)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Security Architecture Crew\n",
        "\n",
        "Designs security architecture recommendations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from security_requirements_system.crews.security_architecture_crew import SecurityArchitectureCrew\n",
        "\n",
        "print(\"Testing Security Architecture Crew...\\n\")\n",
        "\n",
        "# Load dependencies from cache if not in memory\n",
        "if \"architecture_output\" not in globals() or \"components_json\" not in globals() or \"security_controls_json\" not in globals():\n",
        "    print(\"âš ï¸  Loading dependencies from cache...\")\n",
        "    from security_requirements_system.data_models import ArchitectureOutput, DomainSecurityOutput\n",
        "\n",
        "    # Load architecture\n",
        "    if \"architecture_output\" not in globals():\n",
        "        cached = load_cached_output(\"requirements_analysis\")\n",
        "        if cached and \"tasks\" in cached:\n",
        "            arch_task = next((t for t in cached[\"tasks\"] if t[\"name\"] == \"analyze_architecture\"), None)\n",
        "            if arch_task and \"pydantic\" in arch_task:\n",
        "                architecture_output = ArchitectureOutput(**arch_task[\"pydantic\"])\n",
        "                components_json = json.dumps([c.model_dump() for c in architecture_output.components])\n",
        "\n",
        "    # Load security controls\n",
        "    if \"security_controls_json\" not in globals():\n",
        "        cached = load_cached_output(\"domain_security\")\n",
        "        if cached and \"tasks\" in cached and len(cached[\"tasks\"]) > 0:\n",
        "            if \"pydantic\" in cached[\"tasks\"][0]:\n",
        "                security_controls_json = json.dumps(cached[\"tasks\"][0][\"pydantic\"])\n",
        "\n",
        "crew = SecurityArchitectureCrew().crew()\n",
        "result = crew.kickoff(\n",
        "    inputs={\n",
        "        \"requirements_text\": SAMPLE_REQUIREMENTS,\n",
        "        \"architecture_summary\": architecture_output.architecture_summary,\n",
        "        \"components\": components_json,\n",
        "        \"security_controls\": security_controls_json,\n",
        "    }\n",
        ")\n",
        "\n",
        "display_crew_output(result, \"Security Architecture\")\n",
        "save_output(result, \"security_architecture\")\n",
        "\n",
        "security_architecture_output = result.raw\n",
        "print(f\"\\nâœ“ Output length: {len(security_architecture_output)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Implementation Roadmap Crew\n",
        "\n",
        "Creates phased implementation plan.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from security_requirements_system.crews.roadmap_crew import RoadmapCrew\n",
        "\n",
        "print(\"Testing Roadmap Crew...\\n\")\n",
        "\n",
        "# Load dependencies from cache if not in memory\n",
        "if \"security_controls_json\" not in globals() or \"threats_json\" not in globals() or \"compliance_output\" not in globals():\n",
        "    print(\"âš ï¸  Loading dependencies from cache...\")\n",
        "\n",
        "    # Load security controls\n",
        "    if \"security_controls_json\" not in globals():\n",
        "        cached = load_cached_output(\"domain_security\")\n",
        "        if cached and \"tasks\" in cached and len(cached[\"tasks\"]) > 0:\n",
        "            if \"pydantic\" in cached[\"tasks\"][0]:\n",
        "                security_controls_json = json.dumps(cached[\"tasks\"][0][\"pydantic\"])\n",
        "\n",
        "    # Load threats\n",
        "    if \"threats_json\" not in globals():\n",
        "        cached = load_cached_output(\"threat_modeling\")\n",
        "        if cached and \"pydantic\" in cached:\n",
        "            threats_json = json.dumps(cached[\"pydantic\"])\n",
        "\n",
        "    # Load compliance\n",
        "    if \"compliance_output\" not in globals():\n",
        "        cached = load_cached_output(\"compliance\")\n",
        "        if cached:\n",
        "            compliance_output = cached.get(\"raw\", \"\")\n",
        "\n",
        "crew = RoadmapCrew().crew()\n",
        "result = crew.kickoff(\n",
        "    inputs={\n",
        "        \"requirements_text\": SAMPLE_REQUIREMENTS,\n",
        "        \"security_controls\": security_controls_json,\n",
        "        \"threats\": threats_json,\n",
        "        \"compliance_requirements\": compliance_output,\n",
        "    }\n",
        ")\n",
        "\n",
        "display_crew_output(result, \"Implementation Roadmap\")\n",
        "save_output(result, \"roadmap\")\n",
        "\n",
        "roadmap_output = result.raw\n",
        "print(f\"\\nâœ“ Output length: {len(roadmap_output)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Verification Crew\n",
        "\n",
        "Defines verification and testing strategy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from security_requirements_system.crews.verification_crew import VerificationCrew\n",
        "\n",
        "print(\"Testing Verification Crew...\\n\")\n",
        "\n",
        "# Load dependencies from cache if not in memory\n",
        "if \"security_controls_json\" not in globals() or \"compliance_output\" not in globals():\n",
        "    print(\"âš ï¸  Loading dependencies from cache...\")\n",
        "\n",
        "    # Load security controls\n",
        "    if \"security_controls_json\" not in globals():\n",
        "        cached = load_cached_output(\"domain_security\")\n",
        "        if cached and \"tasks\" in cached and len(cached[\"tasks\"]) > 0:\n",
        "            if \"pydantic\" in cached[\"tasks\"][0]:\n",
        "                security_controls_json = json.dumps(cached[\"tasks\"][0][\"pydantic\"])\n",
        "\n",
        "    # Load compliance\n",
        "    if \"compliance_output\" not in globals():\n",
        "        cached = load_cached_output(\"compliance\")\n",
        "        if cached:\n",
        "            compliance_output = cached.get(\"raw\", \"\")\n",
        "\n",
        "crew = VerificationCrew().crew()\n",
        "result = crew.kickoff(\n",
        "    inputs={\n",
        "        \"security_controls\": security_controls_json,\n",
        "        \"compliance_requirements\": compliance_output,\n",
        "        \"owasp_controls\": security_controls_json,\n",
        "    }\n",
        ")\n",
        "\n",
        "display_crew_output(result, \"Verification & Testing\")\n",
        "save_output(result, \"verification\")\n",
        "\n",
        "verification_output = result.raw\n",
        "print(f\"\\nâœ“ Output length: {len(verification_output)} characters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Validation Crew\n",
        "\n",
        "Validates completeness and quality of generated requirements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from security_requirements_system.crews.validation_crew import ValidationCrew\n",
        "\n",
        "print(\"Testing Validation Crew...\\n\")\n",
        "\n",
        "# Load dependencies from cache if not in memory\n",
        "if \"analysis_output\" not in globals() or \"domain_output\" not in globals():\n",
        "    print(\"âš ï¸  Loading dependencies from cache...\")\n",
        "    from security_requirements_system.data_models import AnalysisOutput, DomainSecurityOutput\n",
        "\n",
        "    # Load requirements analysis\n",
        "    if \"analysis_output\" not in globals():\n",
        "        cached = load_cached_output(\"requirements_analysis\")\n",
        "        if cached and \"tasks\" in cached:\n",
        "            analysis_task = next((t for t in cached[\"tasks\"] if t[\"name\"] == \"analyze_requirements\"), None)\n",
        "            if analysis_task and \"pydantic\" in analysis_task:\n",
        "                analysis_output = AnalysisOutput(**analysis_task[\"pydantic\"])\n",
        "\n",
        "    # Load domain security\n",
        "    if \"domain_output\" not in globals():\n",
        "        cached = load_cached_output(\"domain_security\")\n",
        "        if cached and \"tasks\" in cached and len(cached[\"tasks\"]) > 0:\n",
        "            if \"pydantic\" in cached[\"tasks\"][0]:\n",
        "                domain_output = DomainSecurityOutput(**cached[\"tasks\"][0][\"pydantic\"])\n",
        "\n",
        "crew = ValidationCrew().crew()\n",
        "result = crew.kickoff(\n",
        "    inputs={\n",
        "        \"requirements_text\": SAMPLE_REQUIREMENTS,\n",
        "        \"analyzed_requirements\": f\"Application Summary: {analysis_output.application_summary}\\\\nHigh-Level Requirements: {analysis_output.high_level_requirements}\",\n",
        "        \"security_controls\": domain_output.model_dump_json(indent=2),\n",
        "        \"ai_security\": \"No AI components detected\",\n",
        "        \"compliance_requirements\": \"PCI-DSS, GDPR\",\n",
        "    }\n",
        ")\n",
        "\n",
        "display_crew_output(result, \"Validation\")\n",
        "save_output(result, \"validation\")\n",
        "\n",
        "validation_output = result.tasks_output[0].pydantic\n",
        "print(f\"\\nâœ“ Validation score: {validation_output.overall_score:.2f}\")\n",
        "print(f\"âœ“ Validation passed: {validation_output.validation_passed}\")\n",
        "print(f\"\\nDimension scores:\")\n",
        "for dim, score in validation_output.dimension_scores.items():\n",
        "    print(f\"  - {dim}: {score:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "All crew outputs saved to `test_outputs/` directory.\n",
        "\n",
        "Run any cell above to test specific crews. Outputs are cached to JSON files for inspection.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all saved outputs\n",
        "import os\n",
        "\n",
        "output_dir = Path(\"test_outputs\")\n",
        "if output_dir.exists():\n",
        "    print(\"\\nSaved outputs:\")\n",
        "    for file in sorted(output_dir.glob(\"*.json\")):\n",
        "        size = file.stat().st_size / 1024  # KB\n",
        "        print(f\"  - {file.name} ({size:.1f} KB)\")\n",
        "else:\n",
        "    print(\"\\nNo outputs saved yet. Run cells above to generate outputs.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
